{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssHzGnQqrtBs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE4eRXVql7d1",
        "outputId": "b0318062-eec6-4a64-b75a-e81bfe698140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/dogs_and_cats\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/dogs_and_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTopJiPxuqsT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/gdrive/MyDrive/dogs_and_cats/dogs-vs-cats.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/gdrive/MyDrive/dogs_and_cats\")\n",
        "with zipfile.ZipFile(\"/gdrive/MyDrive/dogs_and_cats/train.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/gdrive/MyDrive/dogs_and_cats\")\n",
        "with zipfile.ZipFile(\"/gdrive/MyDrive/dogs_and_cats/test1.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/gdrive/MyDrive/dogs_and_cats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji0F8Vv5vUzx"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"/gdrive/MyDrive/dogs_and_cats/\")\n",
        "IMAGE_DIR =  DATA_DIR / \"train/\"\n",
        "MODEL_PATH = DATA_DIR / \"savel_model/model1/\"\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 64 \n",
        "VALID_SIZE = 0.2\n",
        "IMAGE_SIZE = (200, 200)\n",
        "N_CHANNELS = 3\n",
        "N_CLASSES = 2\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 0.001\n",
        "N_EPOCHS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x61O8jVDpZDK"
      },
      "outputs": [],
      "source": [
        "train_labels = list()\n",
        "for name_image in os.listdir(IMAGE_DIR):\n",
        "  name = name_image.split(\".\")[0]\n",
        "  if name == \"dog\" :\n",
        "    train_labels.append(1)\n",
        "  else : train_labels.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE4HT6JEQvY-"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"image_ids\":os.listdir(IMAGE_DIR), \"labels\": train_labels})\n",
        "df.labels = df.labels.replace({0:\"cat\", 1:\"dog\"})\n",
        "train_df, valid_df = train_test_split(\n",
        "        df, test_size=VALID_SIZE, random_state=RANDOM_SEED, stratify=df.labels,\n",
        ")\n",
        "train_df.reset_index(drop=True ,inplace=True)\n",
        "valid_df.reset_index(drop=True ,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxfkzsLtwyr8",
        "outputId": "7eb214d0-379c-4b8e-e989-c6e8bd36bfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "train_dataset = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    IMAGE_DIR, \n",
        "    x_col='image_ids',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0h7unkxwybV",
        "outputId": "5a3f98d0-5aa9-49c1-b6a2-c0f6d73dce33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "valid_dataset = valid_datagen.flow_from_dataframe(\n",
        "    valid_df, \n",
        "    IMAGE_DIR, \n",
        "    x_col='image_ids',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVgG_reVfXnr"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(*IMAGE_SIZE, N_CHANNELS)),\n",
        "    layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation = \"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2, activation = \"softmax\"),\n",
        "\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-eiERp2l0fc",
        "outputId": "9a19bd40-0a72-46b4-96f8-c9388de9288e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f69636092d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_weights(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQWtxRGxIbrH"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBxIaFIr742Q",
        "outputId": "b48fea98-6d13-4b7d-9d51-f72581b67641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 200, 200, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 200, 200, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 100, 100, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 100, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 100, 100, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 50, 50, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 50, 50, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 25, 25, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 80000)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 80000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               40960512  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,057,730\n",
            "Trainable params: 41,056,258\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEode0enIkdM"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(MODEL_PATH, save_weights_only=True, verbose = 1),\n",
        "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDFk9paBIm8M",
        "outputId": "b31a9485-579d-4aaf-ec75-172b6165b5f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 86/313 [=======>......................] - ETA: 2:35:28 - loss: 0.3175 - accuracy: 0.8614"
          ]
        }
      ],
      "source": [
        "model.fit(train_dataset, validation_data=valid_dataset, callbacks=callbacks, epochs=N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jw9V9HXBOHdF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}